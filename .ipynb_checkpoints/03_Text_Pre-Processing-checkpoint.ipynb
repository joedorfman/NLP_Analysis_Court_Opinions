{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import data\n",
    "from gensim.models import word2vec\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the list of all the appellate cases from the 9th circuit\n",
    "\n",
    "df=pd.read_pickle('./circuit_w_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absolute_url                   /opinion/3066157/san-luis-delta-mendota-water-...\n",
       "attorney                                                                        \n",
       "author_id                                                                   None\n",
       "caseName                       San Luis & Delta-Mendota Water v. Natural Reso...\n",
       "caseNameShort                                                                   \n",
       "citation                                                                    None\n",
       "citeCount                                                                      0\n",
       "cites                          [78617, 104034, 104812, 106566, 108283, 108752...\n",
       "cluster_id                                                               3066157\n",
       "court                                     Court of Appeals for the Ninth Circuit\n",
       "court_citation_string                                                   9th Cir.\n",
       "court_exact                                                                  ca9\n",
       "court_id                                                                     ca9\n",
       "dateArgued                                                                  None\n",
       "dateFiled                                                   2014-03-13T00:00:00Z\n",
       "dateReargued                                                                None\n",
       "dateReargumentDenied                                                        None\n",
       "docketNumber                                                            11-15871\n",
       "docket_id                                                                2923607\n",
       "download_url                   http://cdn.ca9.uscourts.gov/datastore/opinions...\n",
       "id                                                                       3066157\n",
       "joined_by_ids                                                               None\n",
       "judge                                                                           \n",
       "lexisCite                                                                       \n",
       "local_path                     pdf/2014/03/13/san_luis__delta-mendota_water_v...\n",
       "neutralCite                                                                     \n",
       "non_participating_judge_ids                                                 None\n",
       "pagerank                                                                    None\n",
       "panel_ids                                                                   None\n",
       "per_curiam                                                                  None\n",
       "scdb_id                                                                         \n",
       "sibling_ids                                                            [3066157]\n",
       "snippet                                process.\\n\\n<mark>Section</mark> <mark...\n",
       "source                                                                         C\n",
       "status                                                              Precedential\n",
       "status_exact                                                        Precedential\n",
       "suitNature                                                                 Civil\n",
       "timestamp                                            2017-04-18T02:38:09.387999Z\n",
       "type                                                                 010combined\n",
       "text                                           FOR PUBLICATION\\n\\n  UNITED ST...\n",
       "Name: 200, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This the list of all the appellate cases except the 9th circuit\n",
    "\n",
    "df2=pd.read_pickle('./circuit_dc_w_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop out entries that are blank or NAN in the text field.\n",
    "\n",
    "df=df.dropna(subset=['text'])\n",
    "\n",
    "df=df.loc[df['text']!='']\n",
    "\n",
    "df2=df2.dropna(subset=['text'])\n",
    "\n",
    "df2=df2.loc[df2['text']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Matt Brems' lecture notes\n",
    "\n",
    "def review_to_wordlist(sentence):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #    \n",
    "    \n",
    "    # tokenizing and removing punctuation\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z]{3,}')\n",
    "    text_processed=tokenizer.tokenize(sentence)\n",
    "    \n",
    "    legal_words=set(['sec', 'fed', 'reg', 'act', 'cir', 'cert', 'see', 'app', 'soc', 'stat'])\n",
    "    stops=set(stopwords.words('english'))\n",
    "    \n",
    "    # removing any stopwords\n",
    "    text_processed = [word for word in text_processed  if (word.lower() not in stops and \n",
    "                     word.lower() not in legal_words)]\n",
    "          \n",
    "    # make words lower-cased, unless it is an acronym\n",
    "    text_processed = [word.lower() if (word.upper() != word or len(word)>4) else word for word in text_processed ]\n",
    "    \n",
    "    # return a list of words\n",
    "    return (text_processed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Matt Brems' lecture notes.\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( text, tokenizer):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the document into sentences\n",
    "    raw_sentences = tokenizer.tokenize(text.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "#Break each case down into a series of sentances, each of which is a list of words\n",
    "# Assemble a list of all such sentences in the entire corpus\n",
    "\n",
    "\n",
    "train_sentences = []  # Initialize an empty list of sentences\n",
    "counter=0\n",
    "\n",
    "print(\"Parsing sentences from training set\")\n",
    "for case_text in df['text']:\n",
    "    print (counter)\n",
    "    train_sentences += review_to_sentences(case_text, tokenizer)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Word2Vec Model from the texts of all the cases\n",
    "\n",
    "\n",
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 100    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 40          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(train_sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"100features_40minwords_40context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each text field into a list of tokens\n",
    "\n",
    "df['text2']=df['text'].progress_apply(review_to_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each text field into a list of tokens\n",
    "\n",
    "df2['text2']=df2['text'].progress_apply(review_to_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./processed_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_pickle('./dc_processed_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
